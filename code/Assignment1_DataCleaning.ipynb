{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\varun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet') \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filename): \n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f: \n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles = load_json(\"combined_unique_articles.json\") \n",
    "mnt_article = load_json(\"medicalnewstoday_article.json\") \n",
    "reddit_posts = load_json(\"reddit_posts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_news_text(record): \n",
    "    # We assume the 'content' field holds the article text. \n",
    "    return record.get(\"content\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mnt_text(record): \n",
    "    return record.get(\"content\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reddit_text(record): \n",
    "    title = record.get(\"title\", \"\") \n",
    "    body = record.get(\"selftext\", \"\") # Sometimes selftext is empty; if so, we use the title only. \n",
    "    return title + \"\\n\" + body if body else title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_texts = [extract_news_text(rec) for rec in news_articles if extract_news_text(rec).strip() != \"\"] \n",
    "mnt_texts = [extract_mnt_text(mnt_article)] if extract_mnt_text(mnt_article).strip() != \"\" else [] \n",
    "reddit_texts = [extract_reddit_text(rec) for rec in reddit_posts if extract_reddit_text(rec).strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records loaded: 793\n"
     ]
    }
   ],
   "source": [
    "all_texts = news_texts + mnt_texts + reddit_texts \n",
    "df = pd.DataFrame({\"text\": all_texts}) \n",
    "print(\"Total records loaded:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bunge Global (NYSE:BG – Get Free Report) and A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GMO U.S. Quality ETF (NYSEARCA:QLTY – Get Free...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAKELAND, Fla., Feb. 14, 2025 (GLOBE NEWSWIRE)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We independently select these products—if you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If youve been on the hunt for a way to boost y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>GMOs are key to reducing pesticide use in farm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Genetically modified crops: A success story in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>GMOs: Improving nutrition and food quality for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>Why I support GMOs: A farmer's perspective.\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>GMOs: Feeding the world and fighting malnutrit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Bunge Global (NYSE:BG – Get Free Report) and A...\n",
       "1    GMO U.S. Quality ETF (NYSEARCA:QLTY – Get Free...\n",
       "2    LAKELAND, Fla., Feb. 14, 2025 (GLOBE NEWSWIRE)...\n",
       "3    We independently select these products—if you ...\n",
       "4    If youve been on the hunt for a way to boost y...\n",
       "..                                                 ...\n",
       "788  GMOs are key to reducing pesticide use in farm...\n",
       "789  Genetically modified crops: A success story in...\n",
       "790  GMOs: Improving nutrition and food quality for...\n",
       "791  Why I support GMOs: A farmer's perspective.\\nW...\n",
       "792  GMOs: Feeding the world and fighting malnutrit...\n",
       "\n",
       "[793 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text): # Lowercase and remove non-alphabetic characters (keep spaces) \n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text) \n",
    "    text = re.sub(r'\\s+', ' ', text).strip() \n",
    "    return text\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(basic_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bunge global nyse bg get free report and austr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmo u s quality etf nysearca qlty get free rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lakeland fla feb globe newswire a new turmeric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we independently select these products if you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if youve been on the hunt for a way to boost y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>gmos are key to reducing pesticide use in farm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>genetically modified crops a success story in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>gmos improving nutrition and food quality for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>why i support gmos a farmer s perspective with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>gmos feeding the world and fighting malnutriti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text\n",
       "0    bunge global nyse bg get free report and austr...\n",
       "1    gmo u s quality etf nysearca qlty get free rep...\n",
       "2    lakeland fla feb globe newswire a new turmeric...\n",
       "3    we independently select these products if you ...\n",
       "4    if youve been on the hunt for a way to boost y...\n",
       "..                                                 ...\n",
       "788  gmos are key to reducing pesticide use in farm...\n",
       "789  genetically modified crops a success story in ...\n",
       "790  gmos improving nutrition and food quality for ...\n",
       "791  why i support gmos a farmer s perspective with...\n",
       "792  gmos feeding the world and fighting malnutriti...\n",
       "\n",
       "[793 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "label\n",
      "Mildly Anti-GMO      211\n",
      "Mildly Pro-GMO       209\n",
      "Strongly Pro-GMO     194\n",
      "Strongly Anti-GMO    179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def assign_label(text): \n",
    "    score = analyzer.polarity_scores(text)[\"compound\"] # Using thresholds: positive score indicates pro-GMO stance, # negative indicates anti-GMO. We'll split into four categories. \n",
    "    if score >= 0.6: \n",
    "        return \"Strongly Pro-GMO\" \n",
    "    elif score >= 0.01 and score < 0.6:\n",
    "        return \"Mildly Pro-GMO\" \n",
    "    elif score >= -0.4 and score < 0.01: \n",
    "        return \"Mildly Anti-GMO\"    \n",
    "    else: \n",
    "        return \"Strongly Anti-GMO\"\n",
    "\n",
    "df[\"label\"] = df[\"clean_text\"].apply(assign_label) \n",
    "print(\"Label distribution:\") \n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bunge global nyse bg get free report and austr...</td>\n",
       "      <td>Strongly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gmo u s quality etf nysearca qlty get free rep...</td>\n",
       "      <td>Strongly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lakeland fla feb globe newswire a new turmeric...</td>\n",
       "      <td>Strongly Anti-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we independently select these products if you ...</td>\n",
       "      <td>Mildly Anti-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if youve been on the hunt for a way to boost y...</td>\n",
       "      <td>Strongly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>gmos are key to reducing pesticide use in farm...</td>\n",
       "      <td>Mildly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>genetically modified crops a success story in ...</td>\n",
       "      <td>Strongly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>gmos improving nutrition and food quality for ...</td>\n",
       "      <td>Strongly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>why i support gmos a farmer s perspective with...</td>\n",
       "      <td>Strongly Pro-GMO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>gmos feeding the world and fighting malnutriti...</td>\n",
       "      <td>Mildly Pro-GMO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_text              label\n",
       "0    bunge global nyse bg get free report and austr...   Strongly Pro-GMO\n",
       "1    gmo u s quality etf nysearca qlty get free rep...   Strongly Pro-GMO\n",
       "2    lakeland fla feb globe newswire a new turmeric...  Strongly Anti-GMO\n",
       "3    we independently select these products if you ...    Mildly Anti-GMO\n",
       "4    if youve been on the hunt for a way to boost y...   Strongly Pro-GMO\n",
       "..                                                 ...                ...\n",
       "788  gmos are key to reducing pesticide use in farm...     Mildly Pro-GMO\n",
       "789  genetically modified crops a success story in ...   Strongly Pro-GMO\n",
       "790  gmos improving nutrition and food quality for ...   Strongly Pro-GMO\n",
       "791  why i support gmos a farmer s perspective with...   Strongly Pro-GMO\n",
       "792  gmos feeding the world and fighting malnutriti...     Mildly Pro-GMO\n",
       "\n",
       "[793 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames created and saved as CSV files.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 1. Create DataFrame with Stemming\n",
    "# ---------------------------------------------\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return \" \".join([ps.stem(token) for token in tokens])\n",
    "\n",
    "df_stem = df.copy()\n",
    "df_stem['stemmed'] = df_stem['clean_text'].apply(stem_text)\n",
    "\n",
    "# Reorder columns so that \"label\" is the first column.\n",
    "cols = df_stem.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index(\"label\")))\n",
    "df_stem = df_stem[cols]\n",
    "\n",
    "# Optionally, save to CSV\n",
    "df_stem.to_csv(\"df_stem.csv\", index=False)\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Create DataFrame with Lemmatization\n",
    "# ---------------------------------------------\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "df_lemmatize = df.copy()\n",
    "df_lemmatize['lemmatized'] = df_lemmatize['clean_text'].apply(lemmatize_text)\n",
    "\n",
    "cols = df_lemmatize.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index(\"label\")))\n",
    "df_lemmatize = df_lemmatize[cols]\n",
    "\n",
    "df_lemmatize.to_csv(\"df_lemmatize.csv\", index=False)\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. Create DataFrame using CountVectorizer\n",
    "# ---------------------------------------------\n",
    "# Parameters: max_df=0.9, min_df=2, max_features=1000 (adjust as needed)\n",
    "count_vect = CountVectorizer(max_df=0.9, min_df=2, max_features=1000)\n",
    "X_count = count_vect.fit_transform(df['clean_text'])\n",
    "df_count = pd.DataFrame(X_count.toarray(), columns=count_vect.get_feature_names_out())\n",
    "\n",
    "# Add labels as a column from the original df.\n",
    "df_count['label'] = df['label'].values\n",
    "\n",
    "cols = df_count.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index(\"label\")))\n",
    "df_count = df_count[cols]\n",
    "\n",
    "df_count.to_csv(\"df_count.csv\", index=False)\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. Create DataFrame using TfidfVectorizer\n",
    "# ---------------------------------------------\n",
    "tfidf_vect = TfidfVectorizer(max_df=0.9, min_df=2, max_features=1000)\n",
    "X_tfidf = tfidf_vect.fit_transform(df['clean_text'])\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vect.get_feature_names_out())\n",
    "\n",
    "df_tfidf['label'] = df['label'].values\n",
    "\n",
    "cols = df_tfidf.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index(\"label\")))\n",
    "df_tfidf = df_tfidf[cols]\n",
    "\n",
    "df_tfidf.to_csv(\"df_tfidf.csv\", index=False)\n",
    "\n",
    "print(\"DataFrames created and saved as CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed DataFrame:\n",
      "                 label                                            stemmed\n",
      "0     Strongly Pro-GMO  bung global nyse bg get free report and austra...\n",
      "1     Strongly Pro-GMO  gmo u s qualiti etf nysearca qlti get free rep...\n",
      "2    Strongly Anti-GMO  lakeland fla feb globe newswir a new turmer ha...\n",
      "3      Mildly Anti-GMO  we independ select these product if you buy fr...\n",
      "4     Strongly Pro-GMO  if youv been on the hunt for a way to boost yo...\n",
      "..                 ...                                                ...\n",
      "788     Mildly Pro-GMO  gmo are key to reduc pesticid use in farm i m ...\n",
      "789   Strongly Pro-GMO  genet modifi crop a success stori in agricultu...\n",
      "790   Strongly Pro-GMO  gmo improv nutrit and food qualiti for everyon...\n",
      "791   Strongly Pro-GMO  whi i support gmo a farmer s perspect with car...\n",
      "792     Mildly Pro-GMO  gmo feed the world and fight malnutrit farmer ...\n",
      "\n",
      "[793 rows x 2 columns]\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "Lemmatized DataFrame:\n",
      "                 label                                         lemmatized\n",
      "0     Strongly Pro-GMO  bunge global nyse bg get free report and austr...\n",
      "1     Strongly Pro-GMO  gmo u s quality etf nysearca qlty get free rep...\n",
      "2    Strongly Anti-GMO  lakeland fla feb globe newswire a new turmeric...\n",
      "3      Mildly Anti-GMO  we independently select these product if you b...\n",
      "4     Strongly Pro-GMO  if youve been on the hunt for a way to boost y...\n",
      "..                 ...                                                ...\n",
      "788     Mildly Pro-GMO  gmos are key to reducing pesticide use in farm...\n",
      "789   Strongly Pro-GMO  genetically modified crop a success story in a...\n",
      "790   Strongly Pro-GMO  gmos improving nutrition and food quality for ...\n",
      "791   Strongly Pro-GMO  why i support gmos a farmer s perspective with...\n",
      "792     Mildly Pro-GMO  gmos feeding the world and fighting malnutriti...\n",
      "\n",
      "[793 rows x 2 columns]\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "CountVectorizer DataFrame:\n",
      "                 label  abandon  ability  abomination  about  abstract  \\\n",
      "0     Strongly Pro-GMO        0        0            0      0         0   \n",
      "1     Strongly Pro-GMO        0        0            0      0         0   \n",
      "2    Strongly Anti-GMO        0        0            0      0         0   \n",
      "3      Mildly Anti-GMO        0        0            0      0         0   \n",
      "4     Strongly Pro-GMO        0        0            0      0         0   \n",
      "..                 ...      ...      ...          ...    ...       ...   \n",
      "788     Mildly Pro-GMO        0        0            0      1         0   \n",
      "789   Strongly Pro-GMO        0        0            0      0         0   \n",
      "790   Strongly Pro-GMO        0        0            0      0         0   \n",
      "791   Strongly Pro-GMO        0        0            0      0         0   \n",
      "792     Mildly Pro-GMO        0        0            0      0         0   \n",
      "\n",
      "     according  account  acknowledge  across  ...  year  years  yerba  yes  \\\n",
      "0            0        0            0       0  ...     0      0      0    0   \n",
      "1            0        0            0       0  ...     0      0      0    0   \n",
      "2            0        0            0       0  ...     0      0      0    0   \n",
      "3            0        0            0       0  ...     0      0      0    0   \n",
      "4            0        0            0       0  ...     0      0      0    0   \n",
      "..         ...      ...          ...     ...  ...   ...    ...    ...  ...   \n",
      "788          0        0            0       0  ...     0      0      0    0   \n",
      "789          0        0            0       0  ...     0      0      0    0   \n",
      "790          0        0            0       0  ...     0      0      0    0   \n",
      "791          0        0            0       0  ...     0      0      0    0   \n",
      "792          0        0            0       0  ...     0      0      0    0   \n",
      "\n",
      "     yet  yield  yields  york  you  your  \n",
      "0      0      0       0     0    0     0  \n",
      "1      0      0       0     0    0     0  \n",
      "2      0      0       0     0    0     0  \n",
      "3      0      0       0     0    1     0  \n",
      "4      0      0       0     0    0     1  \n",
      "..   ...    ...     ...   ...  ...   ...  \n",
      "788    0      0       0     0    0     0  \n",
      "789    0      0       0     0    0     0  \n",
      "790    0      0       1     0    0     0  \n",
      "791    0      0       0     0    0     0  \n",
      "792    0      0       1     0    0     0  \n",
      "\n",
      "[793 rows x 1000 columns]\n",
      "\n",
      "---------------------------------\n",
      "\n",
      "TfidfVectorizer DataFrame:\n",
      "                 label  abandon  ability  abomination     about  abstract  \\\n",
      "0     Strongly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "1     Strongly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "2    Strongly Anti-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "3      Mildly Anti-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "4     Strongly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "..                 ...      ...      ...          ...       ...       ...   \n",
      "788     Mildly Pro-GMO      0.0      0.0          0.0  0.132266       0.0   \n",
      "789   Strongly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "790   Strongly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "791   Strongly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "792     Mildly Pro-GMO      0.0      0.0          0.0  0.000000       0.0   \n",
      "\n",
      "     according  account  acknowledge  across  ...  year  years  yerba  yes  \\\n",
      "0          0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "1          0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "2          0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "3          0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "4          0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "..         ...      ...          ...     ...  ...   ...    ...    ...  ...   \n",
      "788        0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "789        0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "790        0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "791        0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "792        0.0      0.0          0.0     0.0  ...   0.0    0.0    0.0  0.0   \n",
      "\n",
      "     yet  yield    yields  york       you      your  \n",
      "0    0.0    0.0  0.000000   0.0  0.000000  0.000000  \n",
      "1    0.0    0.0  0.000000   0.0  0.000000  0.000000  \n",
      "2    0.0    0.0  0.000000   0.0  0.000000  0.000000  \n",
      "3    0.0    0.0  0.000000   0.0  0.193452  0.000000  \n",
      "4    0.0    0.0  0.000000   0.0  0.000000  0.211403  \n",
      "..   ...    ...       ...   ...       ...       ...  \n",
      "788  0.0    0.0  0.000000   0.0  0.000000  0.000000  \n",
      "789  0.0    0.0  0.000000   0.0  0.000000  0.000000  \n",
      "790  0.0    0.0  0.189569   0.0  0.000000  0.000000  \n",
      "791  0.0    0.0  0.000000   0.0  0.000000  0.000000  \n",
      "792  0.0    0.0  0.209592   0.0  0.000000  0.000000  \n",
      "\n",
      "[793 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Stemmed DataFrame:\")\n",
    "#df_stem = df_stem.drop(columns=['clean_text'])\n",
    "print(df_stem)\n",
    "print(\"\\n---------------------------------\\n\")\n",
    "\n",
    "print(\"Lemmatized DataFrame:\")\n",
    "#df_lemmatize = df_lemmatize.drop(columns=['clean_text'])\n",
    "print(df_lemmatize)\n",
    "print(\"\\n---------------------------------\\n\")\n",
    "\n",
    "print(\"CountVectorizer DataFrame:\")\n",
    "print(df_count)\n",
    "print(\"\\n---------------------------------\\n\")\n",
    "\n",
    "print(\"TfidfVectorizer DataFrame:\")\n",
    "print(df_tfidf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
