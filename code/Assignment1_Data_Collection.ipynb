{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import praw\n",
    "\n",
    "# =============================\n",
    "# Part 1: NewsAPI Data Fetching\n",
    "# =============================\n",
    "\n",
    "# Replace with your actual NewsAPI key\n",
    "newsapi_key = \"YOUR_NEWSAPI_KEY\"\n",
    "\n",
    "def fetch_newsapi_articles(query=\"GMO\", pages=2):\n",
    "    newsapi_url = \"https://newsapi.org/v2/everything\"\n",
    "    all_articles = []\n",
    "    \n",
    "    for page in range(1, pages + 1):\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"language\": \"en\",\n",
    "            \"pageSize\": 100,         # 100 articles per page\n",
    "            \"page\": page,\n",
    "            \"sortBy\": \"publishedAt\",\n",
    "            \"apiKey\": newsapi_key\n",
    "        }\n",
    "        response = requests.get(newsapi_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            articles = data.get(\"articles\", [])\n",
    "            all_articles.extend(articles)\n",
    "            print(f\"NewsAPI - Page {page}: Retrieved {len(articles)} articles.\")\n",
    "        else:\n",
    "            print(f\"NewsAPI request failed on page {page} with status code: {response.status_code}\")\n",
    "    return all_articles\n",
    "\n",
    "# Fetch data from NewsAPI\n",
    "newsapi_articles = fetch_newsapi_articles()\n",
    "print(\"Total NewsAPI articles retrieved:\", len(newsapi_articles))\n",
    "\n",
    "# Convert fetched data to a JSON-formatted string\n",
    "newsapi_raw_text = json.dumps(newsapi_articles, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Save the raw text data to a file\n",
    "with open(\"newsapi_articles_raw.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(newsapi_raw_text)\n",
    "print(\"Raw NewsAPI data saved as 'newsapi_articles_raw.txt'.\")\n",
    "\n",
    "# Read the raw text file and convert it to a Python object\n",
    "with open(\"newsapi_articles_raw.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    loaded_newsapi_data = json.loads(f.read())\n",
    "\n",
    "# Save the loaded data as a JSON file\n",
    "with open(\"newsapi_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(loaded_newsapi_data, f, indent=4, ensure_ascii=False)\n",
    "print(\"NewsAPI data saved as 'newsapi_articles.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 95 articles for query 'genetically modified food'.\n",
      "Total articles for query 'genetically modified food': 95\n",
      "Articles for query 'genetically modified food' saved to 'newsapi_articles_genetically_modified_food.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_newsapi_articles(query, api_key, page=1, pageSize=100):\n",
    "    newsapi_url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": pageSize,\n",
    "        \"page\": page,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(newsapi_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        print(f\"Retrieved {len(articles)} articles for query '{query}'.\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code} for query '{query}'.\")\n",
    "        articles = []\n",
    "    return articles\n",
    "\n",
    "# Replace with your actual NewsAPI key\n",
    "newsapi_key = \"\"\n",
    "\n",
    "# Use a different query term to avoid overlap with your existing \"GMO\" articles\n",
    "new_query = \"genetically modified food\"\n",
    "\n",
    "# Fetch articles using the new search index\n",
    "new_articles = fetch_newsapi_articles(query=new_query, api_key=newsapi_key, page=1, pageSize=100)\n",
    "print(\"Total articles for query '{}': {}\".format(new_query, len(new_articles)))\n",
    "\n",
    "# Save these new articles to a JSON file\n",
    "with open(\"newsapi_articles_genetically_modified_food.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_articles, f, indent=4, ensure_ascii=False)\n",
    "print(\"Articles for query '{}' saved to 'newsapi_articles_genetically_modified_food.json'.\".format(new_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 12 articles for query 'Transgenic crops'.\n",
      "Total articles for query 'Transgenic crops': 12\n",
      "Articles for query 'Transgenic crops' saved to 'newsapi_articles_transgenic_crops.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_newsapi_articles(query, api_key, page=1, pageSize=100):\n",
    "    newsapi_url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": pageSize,\n",
    "        \"page\": page,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(newsapi_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        print(f\"Retrieved {len(articles)} articles for query '{query}'.\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code} for query '{query}'.\")\n",
    "        articles = []\n",
    "    return articles\n",
    "\n",
    "# Replace with your actual NewsAPI key\n",
    "newsapi_key = \"\"\n",
    "\n",
    "# Use a different query term to avoid overlap with your existing \"GMO\" articles\n",
    "new_query = \"Transgenic crops\"\n",
    "\n",
    "# Fetch articles using the new search index\n",
    "new_articles = fetch_newsapi_articles(query=new_query, api_key=newsapi_key, page=1, pageSize=100)\n",
    "print(\"Total articles for query '{}': {}\".format(new_query, len(new_articles)))\n",
    "\n",
    "# Save these new articles to a JSON file\n",
    "with open(\"newsapi_articles_transgenic_crops.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_articles, f, indent=4, ensure_ascii=False)\n",
    "print(\"Articles for query '{}' saved to 'newsapi_articles_transgenic_crops.json'.\".format(new_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 13 articles for query 'Genetically engineered foods'.\n",
      "Total articles for query 'Genetically engineered foods': 13\n",
      "Articles for query 'Genetically engineered foods' saved to 'newsapi_articles_Genetically_engineered_foods.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_newsapi_articles(query, api_key, page=1, pageSize=100):\n",
    "    newsapi_url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": pageSize,\n",
    "        \"page\": page,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(newsapi_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        print(f\"Retrieved {len(articles)} articles for query '{query}'.\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code} for query '{query}'.\")\n",
    "        articles = []\n",
    "    return articles\n",
    "\n",
    "# Replace with your actual NewsAPI key\n",
    "newsapi_key = \"\"\n",
    "\n",
    "# Use a different query term to avoid overlap with your existing \"GMO\" articles\n",
    "new_query = \"Genetically engineered foods\"\n",
    "\n",
    "# Fetch articles using the new search index\n",
    "new_articles = fetch_newsapi_articles(query=new_query, api_key=newsapi_key, page=1, pageSize=100)\n",
    "print(\"Total articles for query '{}': {}\".format(new_query, len(new_articles)))\n",
    "\n",
    "# Save these new articles to a JSON file\n",
    "with open(\"newsapi_articles_Genetically_engineered_foods.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_articles, f, indent=4, ensure_ascii=False)\n",
    "print(\"Articles for query '{}' saved to 'newsapi_articles_Genetically_engineered_foods.json'.\".format(new_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 articles for query 'Bioengineered agriculture'.\n",
      "Total articles for query 'Bioengineered agriculture': 3\n",
      "Articles for query 'Bioengineered agriculture' saved to 'newsapi_articles_Bioengineered_agriculture.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_newsapi_articles(query, api_key, page=1, pageSize=100):\n",
    "    newsapi_url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": pageSize,\n",
    "        \"page\": page,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(newsapi_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        print(f\"Retrieved {len(articles)} articles for query '{query}'.\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code} for query '{query}'.\")\n",
    "        articles = []\n",
    "    return articles\n",
    "\n",
    "# Replace with your actual NewsAPI key\n",
    "newsapi_key = \"\"\n",
    "\n",
    "# Use a different query term to avoid overlap with your existing \"GMO\" articles\n",
    "new_query = \"Bioengineered agriculture\"\n",
    "\n",
    "# Fetch articles using the new search index\n",
    "new_articles = fetch_newsapi_articles(query=new_query, api_key=newsapi_key, page=1, pageSize=100)\n",
    "print(\"Total articles for query '{}': {}\".format(new_query, len(new_articles)))\n",
    "\n",
    "# Save these new articles to a JSON file\n",
    "with open(\"newsapi_articles_Bioengineered_agriculture.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_articles, f, indent=4, ensure_ascii=False)\n",
    "print(\"Articles for query '{}' saved to 'newsapi_articles_Bioengineered_agriculture.json'.\".format(new_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 98 articles for query 'Agricultural biotechnology'.\n",
      "Total articles for query 'Agricultural biotechnology': 98\n",
      "Articles for query 'Agricultural biotechnology' saved to 'newsapi_articles_Agricultural_biotechnology.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_newsapi_articles(query, api_key, page=1, pageSize=100):\n",
    "    newsapi_url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": pageSize,\n",
    "        \"page\": page,\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"apiKey\": api_key\n",
    "    }\n",
    "    response = requests.get(newsapi_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data.get(\"articles\", [])\n",
    "        print(f\"Retrieved {len(articles)} articles for query '{query}'.\")\n",
    "    else:\n",
    "        print(f\"Request failed with status code: {response.status_code} for query '{query}'.\")\n",
    "        articles = []\n",
    "    return articles\n",
    "\n",
    "# Replace with your actual NewsAPI key\n",
    "newsapi_key = \"\"\n",
    "\n",
    "# Use a different query term to avoid overlap with your existing \"GMO\" articles\n",
    "new_query = \"Agricultural biotechnology\"\n",
    "\n",
    "# Fetch articles using the new search index\n",
    "new_articles = fetch_newsapi_articles(query=new_query, api_key=newsapi_key, page=1, pageSize=100)\n",
    "print(\"Total articles for query '{}': {}\".format(new_query, len(new_articles)))\n",
    "\n",
    "# Save these new articles to a JSON file\n",
    "with open(\"newsapi_articles_Agricultural_biotechnology.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_articles, f, indent=4, ensure_ascii=False)\n",
    "print(\"Articles for query '{}' saved to 'newsapi_articles_Agricultural_biotechnology.json'.\".format(new_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles in newsapi_articles.json: 99\n",
      "Total articles in newsapi_articles_genetically_modified_food.json: 95\n",
      "Total articles in newsapi_articles_transgenic_crops.json: 12\n",
      "Total articles in newsapi_articles_Genetically_engineered_foods.json: 13\n",
      "Total articles in newsapi_articles_Bioengineered_agriculture.json: 3\n",
      "Total articles in newsapi_articles_Agricultural_biotechnology.json: 98\n",
      "Combined articles before deduplication: 320\n",
      "Total unique articles after deduplication: 292\n",
      "Combined unique articles saved to 'combined_unique_articles.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def load_json(filename):\n",
    "    \"\"\"Load JSON data from a file.\"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def deduplicate_articles(articles):\n",
    "    \"\"\"\n",
    "    Deduplicate articles based on their URL.\n",
    "    Returns a list of unique articles.\n",
    "    \"\"\"\n",
    "    seen_urls = set()\n",
    "    unique_articles = []\n",
    "    for article in articles:\n",
    "        url = article.get(\"url\")\n",
    "        if url and url not in seen_urls:\n",
    "            unique_articles.append(article)\n",
    "            seen_urls.add(url)\n",
    "    return unique_articles\n",
    "\n",
    "# Load the articles from the two JSON files\n",
    "articles_gmo = load_json(\"newsapi_articles.json\")\n",
    "articles_gmf = load_json(\"newsapi_articles_genetically_modified_food.json\")\n",
    "articles_tc = load_json(\"newsapi_articles_transgenic_crops.json\")\n",
    "articles_gef = load_json(\"newsapi_articles_Genetically_engineered_foods.json\")\n",
    "articles_bg = load_json(\"newsapi_articles_Bioengineered_agriculture.json\")\n",
    "articles_ag = load_json(\"newsapi_articles_Agricultural_biotechnology.json\")\n",
    "\n",
    "# Print the individual counts\n",
    "print(\"Total articles in newsapi_articles.json:\", len(articles_gmo))\n",
    "print(\"Total articles in newsapi_articles_genetically_modified_food.json:\", len(articles_gmf))\n",
    "print(\"Total articles in newsapi_articles_transgenic_crops.json:\", len(articles_tc))\n",
    "print(\"Total articles in newsapi_articles_Genetically_engineered_foods.json:\", len(articles_gef))\n",
    "print(\"Total articles in newsapi_articles_Bioengineered_agriculture.json:\", len(articles_bg))\n",
    "print(\"Total articles in newsapi_articles_Agricultural_biotechnology.json:\", len(articles_ag))\n",
    "\n",
    "# Combine the two lists\n",
    "combined_articles = articles_gmo + articles_gmf + articles_bg + articles_gef + articles_tc + articles_ag\n",
    "print(\"Combined articles before deduplication:\", len(combined_articles))\n",
    "\n",
    "# Deduplicate the combined list\n",
    "unique_articles = deduplicate_articles(combined_articles)\n",
    "print(\"Total unique articles after deduplication:\", len(unique_articles))\n",
    "\n",
    "# Optionally, save the unique combined articles to a new JSON file\n",
    "with open(\"combined_unique_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(unique_articles, f, indent=4, ensure_ascii=False)\n",
    "print(\"Combined unique articles saved to 'combined_unique_articles.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Reddit data saved as 'reddit_posts_raw.txt'.\n",
      "Reddit data saved as 'reddit_posts.json'.\n",
      "Data fetching and saving complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Part 2: Reddit Data Fetching using PRAW\n",
    "# =============================\n",
    "import requests\n",
    "import json\n",
    "import praw\n",
    "# Replace with your actual Reddit credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"Enter your client ID\",\n",
    "    client_secret=\"Enter your secret key\",\n",
    "    user_agent=\"GMODataCollector:v1.0 (by /u/Enter your reddit user name)\"\n",
    ")\n",
    "\n",
    "def fetch_reddit_posts(query=\"GMO\", limit=500):\n",
    "    reddit_posts = []\n",
    "    # Searching across all subreddits for posts containing the query term\n",
    "    for submission in reddit.subreddit(\"all\").search(query, limit=limit):\n",
    "        post_data = {\n",
    "            \"id\": submission.id,\n",
    "            \"title\": submission.title,\n",
    "            \"selftext\": submission.selftext,  # Post body, if available\n",
    "            \"url\": submission.url,\n",
    "            \"created_utc\": submission.created_utc,\n",
    "            \"score\": submission.score,\n",
    "            \"subreddit\": submission.subreddit.display_name\n",
    "        }\n",
    "        reddit_posts.append(post_data)\n",
    "    return reddit_posts\n",
    "\n",
    "# Fetch data from Reddit\n",
    "reddit_posts1 = fetch_reddit_posts()\n",
    "\n",
    "# Convert Reddit data to a JSON-formatted string\n",
    "reddit_raw_text1 = json.dumps(reddit_posts1, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Save the raw Reddit data to a text file\n",
    "with open(\"reddit_posts_raw1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(reddit_raw_text1)\n",
    "print(\"Raw Reddit data saved as 'reddit_posts_raw.txt'.\")\n",
    "\n",
    "# Read the raw text file and convert it to a Python object\n",
    "with open(\"reddit_posts_raw1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    loaded_reddit_data = json.loads(f.read())\n",
    "\n",
    "# Save the loaded Reddit data as a JSON file\n",
    "with open(\"reddit_posts.json1\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(loaded_reddit_data, f, indent=4, ensure_ascii=False)\n",
    "print(\"Reddit data saved as 'reddit_posts.json'.\")\n",
    "\n",
    "print(\"Data fetching and saving complete.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article content scraped successfully.\n",
      "{'url': 'https://www.medicalnewstoday.com/articles/324576#summary', 'title': 'Pros of GMOs', 'content': 'Engineers design plants using genetically modified organisms (GMOs) to improve taste, nutritional content, and resilience. However, people have concerns over their safety, and there is much debate about the pros and cons of using GMOs.\\n\\nScientists create GMO foods by introducing genetic material, or DNA, from a different organism through genetic engineering.\\n\\nMost of the currently available GMO foods are plants, such as fruit and vegetables.\\n\\nIn the United States, theFood and Drug Administration (FDA)regulates all foods from genetically engineered plants. They must meet the same safety requirements as non-GMO foods.\\n\\nGMO foods arelikely to becomea crucial tool in feeding the world’s growing population, especially in areas with harsh climates. However, there have been concerns about possible risks.\\n\\nThis article discusses the advantages and disadvantages of GMO crops, including their potential effects on human health and the environment.\\n\\nManufacturers use genetic modification to give foods desirable traits.\\n\\nPotential advantages ofGMOcrops include attractiveness to consumers, resilience, nutritional value, and less waste.\\n\\nGMO crops may be increasingly attractive to consumers. Examples of this include apples and potatoes that areless likelyto bruise or turn brown.\\n\\nSome believe that GMO foods may have an enhanced flavor compared to non-GMO foods. However, there isno evidenceto show that genetic modification has any effect on the taste, smell, or appearance of foods in the U.S. In fact, most people cannot tell the difference between GMO and non-GMO foods.\\n\\nMost GMO crops in the U.S. were developed to help farmers. They are more resilient crops that help prevent crop and food loss. Some of the reasons farmers choose to grow GMO cropsinclude:\\n\\nGMO crops may also bemore resistantto harsh climates, such as drought, heat, and salty soils. This can help increase the growth of crops in areas where food security is a concern. Certain genes in GMO foods may also help increase the shelf life of foods, again decreasing food waste.\\n\\nCertain types of GMOs may add nutritional value to foods. Anexample of thisis golden rice. This is a product that is engineered to provide higher levels of vitamin A to consumers. While it can provide nutritional value to those who eat it, especially in areas where vitamin A deficiency is an issue, the growth of this product is not widespread. It is not currently a part of the U.S. food system.\\n\\nGrowing plants that are more resistant to diseases spread by insects or viruses will likely result in higher yields for farmers and a more attractive product. All these factors can contribute to lower costs for the consumer and can ensure that more people have access to quality food.\\n\\nGenetically engineering foods is a relatively new practice, which means the long-term effects on safety are not yet clear.\\n\\nMany concerns about the disadvantages relate to human health. Scientists have not yet shown that GMO foods are harmful to health, but research is ongoing.\\n\\nThere is a small risk that GMO foods can trigger an allergic reaction, but this will only happen if the genetic change triggers the production of an allergen.\\n\\nFor instance, if scientists combine a gene from a Brazil nut with a soybean, there is aslight chancethat a person with a nut allergy could have an allergic reaction to products made with the soybean.\\n\\nTheWorld Health Organization (WHO)discourages genetic engineers from using DNA from allergens unless they can prove that the proteins that the gene produces do not cause allergies.\\n\\nScientists assess the likelihood of GMO foods causing an allergic reaction in humans before a product reaches the market and can prevent its launch if necessary.\\n\\nThere have been concerns that eating GMO foods can contribute to the development ofcancerby raising levels of potentially carcinogenic substances in the body.\\n\\nTheAmerican Cancer Societystates there is no evidence that currently available GMO foods either increase or reduce the risk of cancer.\\n\\nWhile cancer rateshave changedover time in the U.S., there is no evidence that these changes coincide with the introduction of GMO foods. If there is a link, it could take several more years before a trend emerges.\\n\\nSome GMOs contain changes that make them resistant to certainantibiotics. In theory, the genes from these plants could enter humans or animals when they eat them. As a result, the person or animal could also develop antibiotic resistance.\\n\\nThe likelihood of this happening isvery small, but theWHOand other health authorities have guidelines in place to prevent it.\\n\\nIn olderresearch from 2009, some food scientists noted that food DNA can survive as far as the gut, and there have been concerns that this could affect the immune system.\\n\\nSome people have also raised fears that eating GMO food could lead to genetic changes in humans. However, most of the DNA in food — whether GMO or not — either is destroyed by cooking or breaks down before it reaches the large intestine.\\n\\nSmall fragments of DNA from food can and do enter the bloodstream and body organs, but there isno evidencethat they have any impact on genetic makeup or human health.\\n\\nIn olderresearch from 2009, some researchers suggested that GMO foods might impact the liver, kidney, pancreas, and reproductive system. They did not have evidence to confirm this and called for further studies.\\n\\nThe use of GMO cropsmay even reducethe risk of toxicity from some substances, as farmers may be able to reduce the use of pesticides.\\n\\nClimate change and severe weather eventsare disruptingfood production and supply. GMO foods could help maintain supplies in the face of changing environmental conditions and a growing population.\\n\\nGenetically modifying some foods could make them:\\n\\nAlso, a2022 studysuggests GMO foods could help slow climate change by reducing greenhouse gases.\\n\\nEnvironmental concernsinclude:\\n\\nThe risks will vary depending on local conditions.\\n\\nIn the U.S., theFDAdoes not require special labeling for GMO foods. This is because they must meet the same safety standards as other foods, and there should be no need for additional regulation.\\n\\nHowever, a GMO food needs a special label if it is “materially different” from its conventional counterpart.For example:\\n\\nHowever, the2018 National Bioengineered Food Disclosure Standardstates that all foods containing genetically engineered ingredients must now carry the label “derived from bioengineering” or “bioengineered.” Specificsymbolsshow whether a food has been bioengineered.\\n\\nThe following are the most common GMO crops produced and sold in the U.S.:\\n\\nDerivatives of these foods, such as cornstarch and sugar, also feature in other manufactured foods. It is worth noting that99.9%of all sugar beet harvested in the U.S. is GMO, as well as over 90% of all canola, corn, soybean, and cotton.\\n\\nFoods that are bioengineered and products that contain bioengineered foodsmust carrya specific label. If a product does not have this kind of label, it does not contain bioengineered ingredients.\\n\\nFoods that are likely to be GMOinclude:\\n\\nMany GMO crops also become ingredients in other foods, for example:\\n\\nGenetic modification is when scientistsinsertnew DNA into the gene pool of an existing plant.\\n\\nFor this to happen, the following needs to take place:\\n\\nFor thousands of years, people have used processes such as selective breeding or crossbreeding to produce more viable crops. However, changes took a long time to achieve, and it was hard to make specific changes.\\n\\nIn recent years, developments in genetic engineering have allowed scientists to make specific changes more quickly. The crops produced in this way are called GMO crops. The first GMO food to appear on the market was a tomato in1994.\\n\\nBelow, we answer some questions people often ask about GMO foods.\\n\\nThe likelihood that any food derived from corn, cottonseed, soybean, canola, or sugar beet will be GMO food in the U.S. is90%or higher.\\n\\nThere is no specific GMO food to avoid. GMO foods undergostrict testingbefore they can be commercialized. Moreover, this could make them safer than other foods, which do not undergo testing.\\n\\nCurrently, there isno evidencethat GMO foods cause cancer, allergies, or any other health conditions. However, research is ongoing.\\n\\nHealth authorities vet all GMOs and other foods for safety before manufacturers can sell them, and research is ongoing.\\n\\nSo far, scientists have foundno evidencethat commercially available GMO foods are dangerous for health. Environmental concernsincludethe risk of altered genes entering wild species.\\n\\nGenetic modification can make plants resistant to disease and tolerant of herbicides, and therefore, the process can increase the amount of food that farmers can grow. This in turn can reduce food prices and contribute to food security.\\n\\nGMO crops are relatively new, and researchers are still investigating their long-term safety and health effects, but no evidence has yet emerged that currently available GMO foods are harmful to human health.'}\n",
      "\n",
      "Article saved to 'medicalnewstoday_article.json'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# URL of the article to scrape\n",
    "url = \"https://www.medicalnewstoday.com/articles/324576#summary\"\n",
    "\n",
    "# Headers to mimic a real browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Make the request to the webpage\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find the article element by its class\n",
    "    article = soup.find(\"article\", class_=\"article-body\")\n",
    "    if article:\n",
    "        # Optionally, get the title from a header tag (if available)\n",
    "        title_tag = article.find([\"h1\", \"h2\", \"h3\"])\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"No Title Found\"\n",
    "        \n",
    "        # Extract all paragraph tags within the article\n",
    "        paragraphs = article.find_all(\"p\")\n",
    "        # Combine the text from all paragraphs\n",
    "        content = \"\\n\\n\".join([p.get_text(strip=True) for p in paragraphs])\n",
    "        \n",
    "        # Create a dictionary with the scraped data\n",
    "        scraped_data = {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"content\": content\n",
    "        }\n",
    "        \n",
    "        print(\"Article content scraped successfully.\")\n",
    "        print(scraped_data)\n",
    "        \n",
    "        # Save the data to a JSON file\n",
    "        with open(\"medicalnewstoday_article.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(scraped_data, f, indent=4, ensure_ascii=False)\n",
    "        print(\"\\nArticle saved to 'medicalnewstoday_article.json'.\")\n",
    "    else:\n",
    "        print(\"Could not find the article element on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
